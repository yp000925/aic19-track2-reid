{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf500
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red137\green197\blue6;\red255\green255\blue255;\red103\green103\blue103;
\red109\green111\blue3;}
{\*\expandedcolortbl;;\cssrgb\c60000\c80000\c0;\cssrgb\c100000\c100000\c100000;\cssrgb\c47843\c47843\c47843;
\cssrgb\c50196\c50196\c0;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs32 \cf2 \cb3 \expnd0\expndtw0\kerning0
Track 2: City-Scale Multi-Camera Vehicle Re-Identification\cf4 \cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 The dataset contains 56,277 images, where 36,935 of them come from 333 object identities form the training set and 18,290 from the other 333 identities in the test set. An additional 1,052 images are used as queries. On average, each vehicle has 84.50 image signatures from 4.55 camera views. Please refer to the ReadMe.txt file for more details.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0\cf4 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Task\cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 Teams should find the image(s) in the test set that are from the same identity as the objects in each query image. The training set may be exploited for supervised learning.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls2\ilvl0\cf4 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Submission Format\cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 One text file should be submitted containing, on each line, a list of the top 100 matches from the test set for each query object, in ascending order of their distance to the query.\'a0The delimiter is space.\'a0Each match should be\'a0represented\'a0as the ID of the test image, which is an integer\'a0between\'a01\'a0and\'a018,290.\'a0An example submission is given below, where ID
\fs24 q,k
\fs32  denotes the test ID for the k\'92th match of the q\'92th query.\cb1 \
\cb3 ID
\fs24 1,1
\fs32 \'a0ID
\fs24 1,2
\fs32 \'a0\'85 ID
\fs24 1,100
\fs32 \cb1 \
\cb3 ID
\fs24 2,1
\fs32 \'a0ID
\fs24 2,2
\fs32 \'a0\'85 ID
\fs24 2,100
\fs32 \cb1 \
\cb3 \'85\cb1 \
\cb3 ID
\fs24 1052,1
\fs32 \'a0ID
\fs24 1052,2
\fs32 \'a0\'85 ID
\fs24 1052,100
\fs32 \cb1 \
\cb3 The text file containing all predictions should be named \cf5 track2.txt\cf4  and can be archived using Zip (\cf5 track2.zip\cf4 ) or tar+gz (\cf5 track2.tar.gz\cf4 ) to reduce upload time.\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls3\ilvl0\cf4 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Evaluation\cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3 The metric used to rank the performance of each team will be the mean Average Precision (mAP) [4] of the top-K matches, which measures the mean of average precision (the area under the Precision-Recall curve) over all the queries. In our case, K=100. Our evaluation server may also provide other measures, such as the rank-1, rank-5 and rank-10 hit rates, which measure the percentage of the queries that have at least one true positive result ranked within the top 1, 5 or 10 positions, respectively.}